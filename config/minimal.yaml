# Minimal Ollama MCP Client Configuration
# This is a minimal configuration to get started quickly

ollama:
  host: http://localhost:11434
  # model: llama3.2  # Optional: specify a model, or auto-detect will be used

servers:
  - name: filesystem
    type: stdio
    autoConnect: true
    stdio:
      command: mcp-server-filesystem
      args: ['--root', './']

logging:
  level: info

output:
  format: pretty
  colors: true
